{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsxjF1BP2mtC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H6edywQd3TQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. What are the key tasks that machine learning entails? What does data pre-processing imply?\n",
        "\n",
        "### Ans:\n",
        " There are many key tasks that machine learning entails, but some of the most common include:\n",
        "\n",
        "Classification: This is the task of assigning labels to data points. For example, a classification model could be used to label images as containing either a cat or a dog.\n",
        "\n",
        "Regression: This is the task of predicting a continuous value, such as the price of a house or the number of people who will visit a website.\n",
        "\n",
        "Clustering: This is the task of grouping data points together based on their similarities. For example, a clustering model could be used to group customers together based on their purchase history.\n",
        "\n",
        "Anomaly detection: This is the task of identifying data points that are unusual or unexpected. For example, an anomaly detection model could be used to identify fraudulent credit card transactions.\n",
        "\n",
        "Data preprocessing is the process of cleaning and preparing data for machine learning. This can involve tasks such as:\n",
        "\n",
        "Identifying and removing outliers: Outliers are data points that are significantly different from the rest of the data. They can skew the results of machine learning models, so it is important to identify and remove them.\n",
        "Dealing with missing values: Missing values can occur for a variety of reasons, such as data entry errors or incomplete surveys. It is important to deal with missing values in a way that does not bias the results of machine learning models.\n",
        "Encoding categorical data: Categorical data is data that can be placed into categories, such as gender or zip code. It is important to encode categorical data so that machine learning models can understand it.\n",
        "Splitting the data into training and test sets: Once the data has been cleaned and prepared, it is important to split it into training and test sets. The training set is used to train the machine learning model, while the test set is used to evaluate the model's performance.\n",
        "\n",
        "2. Describe quantitative and qualitative data in depth. Make a distinction between the two.\n",
        "Ans:\n",
        "Quantitative data is data that can be measured and expressed in numbers. Examples of quantitative data include height, weight, income, and time. Qualitative data is data that cannot be measured or expressed in numbers. Examples of qualitative data include names, colors, and descriptions.\n",
        "\n",
        "The main difference between quantitative and qualitative data is that quantitative data can be analyzed using statistical methods, while qualitative data cannot.\n",
        "\n",
        "### 3. Create a basic data collection that includes some sample records. Have at least one attribute from each of the machine learning data types.\n",
        "\n",
        "Ans:\n",
        "\n",
        "Here is an example of a basic data collection that includes some sample records and has at least one attribute from each of the machine learning data types:\n",
        "\n",
        "Attribute\tData Type\tSample Record\n",
        "Age\tNumerical\t25\n",
        "Gender\tCategorical\tFemale\n",
        "Income\tNumerical\t$50,000\n",
        "Occupation\tCategorical\tSoftware Engineer\n",
        "\n",
        "### 4. What are the various causes of machine learning data issues? What are the ramifications?\n",
        "### Ans:\n",
        "There are many causes of machine learning data issues. Some of the most common include:\n",
        "\n",
        "Data Imbalance: This occurs when there is an unequal distribution of data points among the different classes. For example, if you are trying to train a model to classify images of dogs and cats, but there are far more images of dogs than cats, the model will be biased towards predicting that all images are dogs.\n",
        "Data Noise: This occurs when there are errors or inconsistencies in the data. For example, if an image of a dog is labeled as a cat, this will introduce noise into the data and make it more difficult for the model to learn.\n",
        "Data Bias: This occurs when the data is not representative of the real world. For example, if you are trying to train a model to predict the price of a house, but the data only includes houses in a specific city, the model will be biased towards predicting the prices of houses in that city.\n",
        "\n",
        " Ramifications of Machine Learning Data Issues\n",
        "\n",
        "Machine learning data issues can have a significant impact on the performance of machine learning models. If the data is not clean and balanced, the model will be less accurate. If the data is noisy or biased, the model will be less reliable.\n",
        "\n",
        "5. Demonstrate various approaches to categorical data exploration with appropriate examples.\n",
        "\n",
        "There are many different approaches to categorical data exploration. Some of the most common include:\n",
        "\n",
        "Frequency Distributions: This involves counting the number of times each category appears in the data.\n",
        "Bar Charts: This involves creating a bar chart for each category, with the height of each bar representing the frequency of that category.\n",
        "Pie Charts: This involves creating a pie chart for each category, with the size of each slice representing the frequency of that category.\n",
        "Crosstabulations: This involves creating a table that shows the frequency of each category for each variable in the data.\n",
        "\n",
        "6. How would the learning activity be affected if certain variables have missing values? Having said\n",
        "that, what can be done about it?\n",
        "\n",
        "If certain variables have missing values, it can have a significant impact on the learning activity. This is because the machine learning model will not be able to learn from the data that is missing. There are a few things that can be done to deal with missing values. One option is to simply ignore the data points that have missing values. However, this can lead to a loss of information and can make the model less accurate. Another option is to impute the missing values. This involves estimating the missing values using the data that is available. There are a number of different imputation methods that can be used. The best method to use will depend on the specific data set and the goals of the analysis.\n",
        "\n",
        "\n",
        "7. Describe the various methods for dealing with missing data values in depth.\n",
        "\n",
        "\n",
        "Sure, here are the various methods for dealing with missing data values in depth:\n",
        "\n",
        "Ignore the data points that have missing values. This is the simplest method, but it can lead to a loss of information and can make the model less accurate.\n",
        "Impute the missing values. This involves estimating the missing values using the data that is available. There are a number of different imputation methods that can be used. The best method to use will depend on the specific data set and the goals of the analysis.\n",
        "Mean imputation: This involves replacing the missing values with the mean of the values for that variable. This is a simple method, but it can lead to bias if the data is not normally distributed.\n",
        "Median imputation: This involves replacing the missing values with the median of the values for that variable. This is a more robust method than mean imputation, as it is not affected by outliers.\n",
        "K-nearest neighbors imputation: This involves replacing the missing values with the values of the k nearest neighbors, where k is a user-defined parameter. This is a more complex method than mean or median imputation, but it can be more accurate.\n",
        "Complete case analysis. This involves only using the data points that do not have missing values. This can lead to a biased sample, so it is important to be careful when using this method.\n",
        "Pairwise deletion. This involves only using the data points that have values for both the variable with the missing value and the variable that is being analyzed. This can also lead to a biased sample, so it is important to be careful when using this method.\n",
        "Maximum likelihood. This involves using a statistical method to estimate the missing values. This method is more complex than the other methods, but it can be more accurate.\n",
        "\n",
        "8. What are the various data pre-processing techniques? Explain dimensionality reduction and\n",
        "function selection in a few words.\n",
        "\n",
        "There are a number of different data pre-processing techniques. Some of the most common techniques include:\n",
        "\n",
        "Data cleaning: This involves identifying and correcting errors in the data.\n",
        "Data integration: This involves combining data from different sources.\n",
        "Data transformation: This involves changing the format of the data.\n",
        "Data reduction: This involves reducing the size of the data.\n",
        "Feature selection: This involves selecting the most important features from the data.\n",
        "Dimensionality reduction is a data pre-processing technique that reduces the number of dimensions in the data. This can be done by using a number of different methods, such as principal component analysis (PCA) and factor analysis. Function selection is a data pre-processing technique that selects the most important functions from the data. This can be done by using a number of different methods, such as stepwise selection and recursive feature elimination.\n",
        "\n",
        "### 9.\n",
        "\n",
        "i. What is the IQR? What criteria are used to assess it?\n",
        "\n",
        "ii. Describe the various components of a box plot in detail? When will the lower whisker\n",
        "surpass the upper whisker in length? How can box plots be used to identify outliers?\n",
        "\n",
        "The interquartile range (IQR) is a measure of variability that is calculated by taking the difference between the third and first quartiles of a data set. The IQR is a more robust measure of variability than the standard deviation, as it is not affected by outliers. The criteria used to assess the IQR are:\n",
        "\n",
        "Code snippet\n",
        "* The IQR should be large enough to capture the majority of the data.\n",
        "* The IQR should not be too large, as this could indicate that there is a\n",
        "\n",
        "### 10. Make brief notes on any two of the following:\n",
        "\n",
        "1. Data collected at regular intervals\n",
        "\n",
        "2. The gap between the quartiles\n",
        "\n",
        "3. Use a cross-tab\n",
        "\n",
        "1. Make a comparison between:\n",
        "\n",
        "1. Data with nominal and ordinal values\n",
        "\n",
        "2. Histogram and box plot\n",
        "\n",
        "3. The average and median\n",
        "\n",
        "#### Data collected at regular intervals\n",
        "Data collected at regular intervals is called time series data. Time series data can be used to track trends over time, such as the stock market, the weather, or the population of a city. Time series data can also be used to forecast future values, such as the price of a stock or the number of people who will visit a website.\n",
        "\n",
        "#### The gap between the quartiles\n",
        "The gap between the quartiles is called the interquartile range (IQR). The IQR is a measure of variability that is not affected by outliers. The IQR is calculated by taking the difference between the third and first quartiles.\n",
        "\n",
        "#### Use a cross-tab\n",
        "A cross-tab is a table that shows the frequency of each category for each variable in the data. Cross-tabs can be used to explore the relationships between variables. For example, a cross-tab could be used to show the relationship between gender and income.\n",
        "\n",
        "#### Comparison between data with nominal and ordinal values\n",
        "Nominal data is data that can be categorized but cannot be ranked. For example, the data \"red, green, blue\" is nominal data. Ordinal data is data that can be ranked but cannot be measured in terms of size or quantity. For example, the data \"first, second, third\" is ordinal data.\n",
        "\n",
        "Nominal data can be analyzed using statistical techniques such as frequency distributions and cross-tabs. Ordinal data can be analyzed using statistical techniques such as rank correlation and analysis of variance.\n",
        "\n",
        "#### Comparison between histogram and box plot\n",
        "A histogram is a graphical representation of the distribution of data. It is a bar chart that shows the frequency of each value in the data. A box plot is a graphical representation of the distribution of data. It shows the median, the first and third quartiles, and the minimum and maximum values of the data.\n",
        "\n",
        "Histograms are better for showing the shape of the distribution of data. Box plots are better for showing the spread of the data and for identifying outliers.\n",
        "\n",
        "#### Comparison between the average and median\n",
        "The average is the sum of the values in a data set divided by the number of values in the data set. The median is the middle value in a data set when the values are ranked from least to greatest.\n",
        "\n",
        "The average is more sensitive to outliers than the median. The median is a better measure of central tendency for data that is skewed or has outliers.\n"
      ],
      "metadata": {
        "id": "k6nCiIkC3T_D"
      }
    }
  ]
}